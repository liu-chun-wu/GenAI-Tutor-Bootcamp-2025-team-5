{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Install and Imports"],"metadata":{"id":"mlR2JuH_vvxe"}},{"cell_type":"code","source":["!pip install pypdf\n","!pip install google-generativeai\n","!pip install chromadb\n","!pip install typing"],"metadata":{"id":"n8Cug9oevvb3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYNfcpgTvsZM"},"outputs":[],"source":["import requests\n","from pypdf import PdfReader\n","import os\n","import re\n","import google.generativeai as genai\n","from chromadb import Documents, EmbeddingFunction, Embeddings\n","import chromadb\n","from chromadb.config import Settings\n","from typing import List"]},{"cell_type":"markdown","source":["# Download and load PDF"],"metadata":{"id":"ATPAganzwKjS"}},{"cell_type":"code","source":["def download_pdf(url, save_path):\n","    response = requests.get(url)\n","    with open(save_path, 'wb') as f:\n","        f.write(response.content)\n","\n","def load_pdf(file_path):\n","    reader = PdfReader(file_path)\n","    text = \"\"\n","    for page in reader.pages:\n","        page_text = page.extract_text()\n","        if page_text:\n","            text += page_text\n","    return text"],"metadata":{"id":"VpBgUKEGv0zG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ToDo:\n","- Text splitting\n","- ChromaDB\n","- Prompt Construction"],"metadata":{"id":"YIECEUcewUML"}},{"cell_type":"code","source":["# TODO: Students implement text splitting function\n","def split_text(text):\n","    \"\"\"\n","    Split the input text into meaningful chunks.\n","    Returns a list of text chunks.\n","    \"\"\"\n","    pass\n","\n","# Custom embedding function using Gemini API\n","class GeminiEmbeddingFunction(EmbeddingFunction):\n","    def __call__(self, input: Documents) -> Embeddings:\n","        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n","        genai.configure(api_key=gemini_api_key)\n","        model = \"models/embedding-001\"\n","        title = \"Custom query\"\n","        return genai.embed_content(model=model, content=input, task_type=\"retrieval_document\", title=title)[\"embedding\"]\n","\n","# TODO: Students implement ChromaDB creation and querying\n","def create_chroma_db(documents: List[str], path: str, name: str):\n","    \"\"\"\n","    Create a ChromaDB collection with the provided documents.\n","    Returns the database instance and name.\n","\n","    Hint: Use the following to create the client:\n","    client = chromadb.Client(Settings(\n","        chroma_db_impl=\"duckdb+parquet\",\n","        persist_directory=path\n","    ))\n","    \"\"\"\n","    pass\n","\n","def get_relevant_passage(query: str, db, n_results: int):\n","    \"\"\"\n","    Retrieve the most relevant passages for the given query.\n","    Returns a list of relevant text passages.\n","    \"\"\"\n","    pass\n","\n","# TODO: Students implement prompt construction\n","def make_rag_prompt(query: str, relevant_passage: str):\n","    \"\"\"\n","    Construct a prompt for the generation model using the query and retrieved passage.\n","    Returns the formatted prompt string.\n","    \"\"\"\n","    pass"],"metadata":{"id":"fSoJUWJiv3um"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LLM Response Generation"],"metadata":{"id":"YSO0EfflwBUa"}},{"cell_type":"code","source":["def generate_answer(prompt: str):\n","    \"\"\"Generate answer using Gemini Pro API\"\"\"\n","    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n","    if not gemini_api_key:\n","        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n","    genai.configure(api_key=gemini_api_key)\n","    model = genai.GenerativeModel('gemini-pro')\n","    result = model.generate_content(prompt)\n","    return result.text"],"metadata":{"id":"toYV28pPv_hj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main execution\n","## ToDo:\n"," - Chat history\n"," - Multiple file injest"],"metadata":{"id":"4LyBBDZfwlzl"}},{"cell_type":"code","source":["def main():\n","    # Set up configurations\n","    pdf_url = \"https://services.google.com/fh/files/misc/ai_adoption_framework_whitepaper.pdf\"\n","    pdf_path = \"ai_adoption_framework_whitepaper.pdf\"\n","    db_folder = \"chroma_db\"\n","    db_name = \"rag_experiment\"\n","\n","    # Create database directory\n","    if not os.path.exists(db_folder):\n","        os.makedirs(db_folder)\n","\n","    # Download and process PDF\n","    download_pdf(pdf_url, pdf_path)\n","    pdf_text = load_pdf(pdf_path)\n","\n","    # Split text into chunks\n","    chunked_text = split_text(pdf_text)\n","\n","    # Create and set up database\n","    db_path = os.path.join(os.getcwd(), db_folder)\n","    db, _ = create_chroma_db(chunked_text, db_path, db_name)\n","\n","    # Process user query\n","    query = input(\"Please enter your query: \")\n","    relevant_text = get_relevant_passage(query, db, n_results=3)\n","\n","    # Generate and display answer\n","    if relevant_text:\n","        final_prompt = make_rag_prompt(query, \"\".join(relevant_text))\n","        answer = generate_answer(final_prompt)\n","        print(\"\\nGenerated Answer:\", answer)\n","    else:\n","        print(\"No relevant information found for the given query.\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"VwaM3J70v1IM"},"execution_count":null,"outputs":[]}]}